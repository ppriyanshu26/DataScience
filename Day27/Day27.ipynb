{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c63c73",
   "metadata": {},
   "source": [
    "# **üîÅ Recurrent Neural Networks**\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Sequential Input\n",
    "- Designed for **sequential data**: text, time series, speech, etc.\n",
    "- Processes input **step-by-step**, maintaining memory of past inputs.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Recurrent Neurons\n",
    "- Each neuron takes input **and** previous output (hidden state).\n",
    "- Has a feedback loop that enables **memory**.\n",
    "- Formula: `h‚Çú = f(Wx‚Çú + Uh‚Çú‚Çã‚ÇÅ + b)`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚õìÔ∏è Hidden State\n",
    "- Captures **context** from previous time steps.\n",
    "- Passed from one time step to the next.\n",
    "- Enables learning of time-dependent patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Input / Output\n",
    "- Input: A sequence (e.g., sentence = [word1, word2, ...])\n",
    "- Output can be:\n",
    "  - One-to-One (e.g. sentiment classification)\n",
    "  - One-to-Many (e.g. image captioning)\n",
    "  - Many-to-One (e.g. sequence classification)\n",
    "  - Many-to-Many (e.g. translation)\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Activation Function\n",
    "- Commonly uses **tanh** or **ReLU** for hidden state.\n",
    "- **Softmax** at output for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ôªÔ∏è Backpropagation Through Time (BPTT)\n",
    "- Extension of backpropagation for RNNs.\n",
    "- Unrolls the network through time steps.\n",
    "- Adjusts weights by computing gradients over all steps.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Challenges\n",
    "- **Vanishing/exploding gradients** in long sequences.\n",
    "- Solved using advanced RNNs like:\n",
    "  - **LSTM (Long Short-Term Memory)** üì¶\n",
    "  - **GRU (Gated Recurrent Unit)** üîê\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "data = pd.read_csv(\"monthly_milk_production.csv\")\n",
    "data.columns = ['Date','Production']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data.set_index(\"Date\", inplace=True)\n",
    "production = data[\"Production\"].astype(float).values.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing\n",
    "\n",
    "window_size = 12\n",
    "X = []\n",
    "y = []\n",
    "target_dates = data.index[window_size:]\n",
    "\n",
    "for i in range(window_size, len(scaled_data)):\n",
    "    X.append(scaled_data[i - window_size : i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8db421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(X, y, target_dates, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions).flatten()\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_test - predictions) ** 2))\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label=\"Actual Production\")\n",
    "plt.plot(dates_test, predictions, label=\"Predicted Production\")\n",
    "plt.title(\"Actual vs Predicted Production\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Production (pounds per cow)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
